{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dc0e614",
   "metadata": {},
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15b821ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Operations\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# For Progress Bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92535fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "config = {\n",
    "    'seed': 42,   \n",
    "    'valid_ratio': 0.3,\n",
    "    'n_epochs': 10,        \n",
    "    'batch_size': 64, \n",
    "    'learning_rate': 5e-5,              \n",
    "    'early_stop': 3,    \n",
    "    'save_path': './models/model.ckpt',  # model will be saved here.\n",
    "    'data_path': './DataSet/npz_new/',\n",
    "    'data_file': [\"cat_eval\",\"cat_train\",\n",
    "                  \"dog_eval\", \"dog_train\",\n",
    "                  \"other_eval\",\"other_train\"],\n",
    "}\n",
    "def same_seed(seed): \n",
    "    '''Fixes random number generator seeds for reproducibility.'''\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "same_seed(config['seed'])\n",
    "if not os.path.isdir('./models'):\n",
    "    os.mkdir('./models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe5d0c6",
   "metadata": {},
   "source": [
    "# Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd44e85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyM2NetDataset(Dataset):\n",
    "    '''\n",
    "    x: audio mfcc vector   44x13x1.\n",
    "    y: image vector        32x32x3\n",
    "    y: Targets:(cat,dog,duck,rabbit), if none, do prediction.\n",
    "    '''\n",
    "    def __init__(self, x,y,z=None):\n",
    "        if y is None:\n",
    "            self.z = z\n",
    "        else:\n",
    "            self.z = torch.FloatTensor(z)\n",
    "        self.x = torch.FloatTensor(x)\n",
    "        self.y = torch.FloatTensor(y)\n",
    "    def __getitem__(self, idx):\n",
    "        if self.z is None:\n",
    "            return self.x[idx],self.y[idx]\n",
    "        else:\n",
    "            return self.x[idx], self.y[idx], self.z[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "565e4b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeparableConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, bias=False):\n",
    "        super(SeparableConv2d, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channels,in_channels,kernel_size,groups=in_channels,padding=1)\n",
    "        self.pointwise = nn.Conv2d(in_channels,out_channels,kernel_size=kernel_size,padding=1)\n",
    "        self.outlayer = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.pointwise(out)\n",
    "        out = self.outlayer(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class depthwise_separable_conv(nn.Module):\n",
    "    def __init__(self, nin, kernels_per_layer, nout): \n",
    "        super(depthwise_separable_conv, self).__init__() \n",
    "        self.depthwise = nn.Conv2d(nin, nin * kernels_per_layer, kernel_size=3, padding=1, groups=nin) \n",
    "        self.pointwise = nn.Conv2d(nin * kernels_per_layer, nout, kernel_size=1) \n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x): \n",
    "        out = self.depthwise(x) \n",
    "        out = self.pointwise(out)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "class myConv2d(nn.Module):\n",
    "    def __init__(self,input_channels,output_channels,kernel_size,dense_dim,bn_dim):\n",
    "        super(myConv2d, self).__init__()\n",
    "        self.conv2d = nn.Sequential(\n",
    "            nn.Conv2d(input_channels,output_channels,kernel_size,padding=1),\n",
    "            nn.BatchNorm2d(bn_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        ########### use Speratle conv ##################\n",
    "        self.layer1 = nn.Sequential(\n",
    "            depthwise_separable_conv(output_channels,3,32),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            depthwise_separable_conv(32,3,output_channels),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        ##################################################\n",
    "        \n",
    "        \n",
    "#         ######### use normal conv #########################\n",
    "#         self.layer1 = nn.Sequential(\n",
    "#             nn.Conv2d(output_channels,32,kernel_size,padding=1),\n",
    "#             nn.MaxPool2d((2,2)),\n",
    "#             nn.Dropout(0.2)\n",
    "#         )\n",
    "#         self.layer2 = nn.Sequential(\n",
    "#             nn.Conv2d(32,output_channels,kernel_size,padding=1),\n",
    "#             nn.MaxPool2d((2,2)),\n",
    "#             nn.Dropout(0.2)\n",
    "#         )\n",
    "#         #################################################\n",
    "        self.outlayer = nn.Sequential(\n",
    "            nn.Linear(dense_dim,output_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        out = self.conv2d(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = torch.flatten(out,start_dim=1)\n",
    "        out = self.outlayer(out)\n",
    "        return out\n",
    "    \n",
    "class Tiny2Net(nn.Module):\n",
    "    def __init__(self, labels,device):\n",
    "        super(Tiny2Net, self).__init__()\n",
    "        \n",
    "        self.videoNet = myConv2d(3,64,(3,3),16384,64)  #(3,64,(3,3),4096,32)\n",
    "        self.audioNet = myConv2d(1,64,(3,3),2112,64) #(1,64,(3,3),2112,44)\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(64,labels),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        self.device=device\n",
    "        \n",
    "    def forward(self,x,y):\n",
    "        \"\"\"\n",
    "        input x   MFCC Vector     size:  44x13x1\n",
    "        input y   Image Vector   size: 32x32x3\n",
    "        \"\"\"\n",
    "        x_noise, y_noise = torch.rand_like(x).to(device), torch.rand_like(y).to(device)\n",
    "        x = self.audioNet(x+x_noise.detach()) #audio\n",
    "        y = self.videoNet(y+y_noise.detach())\n",
    "        \n",
    "        z = torch.cat((x,y),1)\n",
    "        z = self.layer1(z)\n",
    "        z = self.layer2(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd967a56",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "682fd92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(path,dataList):\n",
    "    def getName(base,file):\n",
    "        return base+file+'.npz'\n",
    "    dataset={}\n",
    "    for item in dataList:\n",
    "        dataset[item]=np.load(getName(path,item))\n",
    "        \n",
    "    return dataset\n",
    "\n",
    "def train_valid_split(x,y,z, valid_ratio,seed):\n",
    "    '''Split provided training data into training set and validation set'''\n",
    "    valid_set_size = int(valid_ratio * len(x)) \n",
    "    train_set_size = len(x) - valid_set_size\n",
    "    data_index = np.arange(len(x))\n",
    "    train_index, valid_index = random_split(data_index, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))\n",
    "    train_index, valid_index = np.array(train_index), np.array(valid_index)\n",
    "\n",
    "    return x[train_index],y[train_index],z[train_index],x[valid_index],y[valid_index],z[valid_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c8630c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17064, 1, 44, 13)\n",
      "(17064, 3, 64, 64)\n",
      "(17064, 3)\n",
      "7312\n"
     ]
    }
   ],
   "source": [
    "data = loadData(config['data_path'],config['data_file'])\n",
    "# 按照种类加载\n",
    "X = [None,None,None]\n",
    "Y = [None,None,None]\n",
    "Z = [None,None,None]\n",
    "label=2\n",
    "for k,v in data.items():\n",
    "    if 'cat' in k:\n",
    "        label=0\n",
    "    elif 'dog' in k:\n",
    "        label=1\n",
    "    else:\n",
    "        label=2\n",
    "        \n",
    "    if X[label] is None:\n",
    "        X[label] = v[\"x\"]\n",
    "        Y[label] = v[\"y\"]\n",
    "        Z[label] = v[\"z\"]\n",
    "    else:\n",
    "        X[label] = np.concatenate((X[label], v[\"x\"]), axis=0)\n",
    "        Y[label] = np.concatenate((Y[label], v[\"y\"]), axis=0)\n",
    "        Z[label] = np.concatenate((Z[label], v[\"z\"]), axis=0)\n",
    "# print(X,Y,Z)\n",
    "# 按照种类split\n",
    "TRAIN_X =  [None,None,None]\n",
    "TRAIN_Y = [None,None,None]\n",
    "TRAIN_Z = [None,None,None]\n",
    "VAL_X =  [None,None,None]\n",
    "VAL_Y =  [None,None,None]\n",
    "VAL_Z =  [None,None,None]\n",
    "for i in [0,1,2]:\n",
    "    TRAIN_X[i],TRAIN_Y[i],TRAIN_Z[i],VAL_X[i],VAL_Y[i],VAL_Z[i]=\\\n",
    "                            train_valid_split(X[i],Y[i],Z[i],config['valid_ratio'],config['seed'])\n",
    "    \n",
    "# 合并TRAIN, VAL\n",
    "train_x,train_y,train_z = TRAIN_X[0],TRAIN_Y[0],TRAIN_Z[0]\n",
    "val_x,val_y,val_z = VAL_X[0],VAL_Y[0],VAL_Z[0]\n",
    "for i in [1,2]:\n",
    "    train_x = np.concatenate((train_x,TRAIN_X[i]),axis=0)\n",
    "    train_y = np.concatenate((train_y,TRAIN_Y[i]),axis=0)\n",
    "    train_z = np.concatenate((train_z,TRAIN_Z[i]),axis=0)\n",
    "    val_x = np.concatenate((val_x,VAL_X[i]),axis=0)\n",
    "    val_y = np.concatenate((val_y,VAL_Y[i]),axis=0)\n",
    "    val_z = np.concatenate((val_z,VAL_Z[i]),axis=0)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(train_z.shape)\n",
    "print(val_x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdb47514",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = TinyM2NetDataset(train_x,train_y,train_z),  TinyM2NetDataset(val_x,val_y,val_z)\n",
    "\n",
    "# Pytorch data loader loads pytorch dataset into batches.\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03cd2ac",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c46fbad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    }
   ],
   "source": [
    "model = Tiny2Net(val_z.shape[-1], device).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=1e-5, amsgrad=False)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.975, last_epoch=-1, verbose=True)\n",
    "writer = SummaryWriter()  # Writer of tensoboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5947a16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.8750e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]: Train loss: 1.0119,Train acc: 0.5108,Valid loss: 0.9575,Valid acc: 0.5916\n",
      "Saving model with loss 0.957...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.7531e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10]: Train loss: 0.9431,Train acc: 0.5963,Valid loss: 0.9328,Valid acc: 0.6068\n",
      "Saving model with loss 0.933...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.6343e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10]: Train loss: 0.9177,Train acc: 0.6251,Valid loss: 0.9016,Valid acc: 0.6444\n",
      "Saving model with loss 0.902...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ..."
     ]
    }
   ],
   "source": [
    "n_epochs, best_loss, step, early_stop_count = config['n_epochs'], math.inf, 0, 0\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()  # Set the model to train mode.\n",
    "    loss_record = []\n",
    "    acc_record = []\n",
    "    train_pbar = tqdm(train_loader, position=0, leave=True)\n",
    "\n",
    "    for x, y, z in train_pbar:\n",
    "        optimizer.zero_grad()  # Set gradient to zero.\n",
    "\n",
    "        x, y, z = x.to(device), y.to(device), z.to(device)\n",
    "        pred = model(x, y)\n",
    "        #             print(\"train: \",pred)\n",
    "        target = z.argmax(dim=1, keepdim=False)\n",
    "        loss = criterion(pred, target)\n",
    "        loss.backward()  # Compute gradient(backpropagation).\n",
    "        optimizer.step()  # Update parameters.\n",
    "        step += 1\n",
    "        loss_record.append(torch.mean(loss).detach().item())\n",
    "        train_correct = torch.argmax(pred, dim=1) == torch.argmax(z, dim=1)\n",
    "        train_accuracy = torch.mean(train_correct.float())\n",
    "        acc_record.append(train_accuracy)\n",
    "        writer.add_scalar('Acc/train', train_accuracy, step)\n",
    "        writer.add_scalar('Loss/train', torch.mean(loss), step)\n",
    "        # Display current epoch number and loss on tqdm progress bar.\n",
    "        train_pbar.set_description(f'Epoch [{epoch + 1}/{n_epochs}]')\n",
    "        train_pbar.set_postfix({'loss': loss.detach().item()})\n",
    "        train_pbar.set_postfix({'Acc': train_accuracy.detach().item()})\n",
    "    scheduler.step()\n",
    "    mean_train_loss = sum(loss_record) / len(loss_record)\n",
    "    mean_train_acc = sum(acc_record) / len(acc_record)\n",
    "    #writer.add_scalar('Loss/train', mean_train_loss, step)\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode.\n",
    "    loss_record = []\n",
    "    acc_record = []\n",
    "    for x, y, z in valid_loader:\n",
    "        x, y, z = x.to(device), y.to(device), z.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(x, y)\n",
    "            target = z.argmax(dim=1, keepdim=False)\n",
    "            loss = criterion(pred, target)\n",
    "        val_correct = torch.argmax(pred, dim=1) == torch.argmax(z, dim=1)\n",
    "        val_accuracy = torch.mean(val_correct.float())\n",
    "        acc_record.append(val_accuracy)\n",
    "        writer.add_scalar('Acc/valid', val_accuracy, step)\n",
    "        writer.add_scalar('Loss/valid', torch.mean(loss), step)\n",
    "        loss_record.append(torch.mean(loss).item())\n",
    "        \n",
    "    mean_valid_loss = sum(loss_record) / len(loss_record)\n",
    "    mean_valid_acc = sum(acc_record) / len(acc_record)\n",
    "    print(f'Epoch [{epoch + 1}/{n_epochs}]: Train loss: {mean_train_loss:.4f},Train acc: {mean_train_acc:.4f},Valid loss: {mean_valid_loss:.4f},Valid acc: {mean_valid_acc:.4f}')\n",
    "    #writer.add_scalar('Loss/valid', mean_valid_loss, step)\n",
    "\n",
    "    if mean_valid_loss < best_loss:\n",
    "        best_loss = mean_valid_loss\n",
    "        torch.save(model.state_dict(), config['save_path']+str(best_loss))  # Save the best model\n",
    "        print('Saving model with loss {:.3f}...'.format(best_loss))\n",
    "        early_stop_count = 0\n",
    "    else:\n",
    "        early_stop_count += 1\n",
    "    \n",
    "    #if early_stop_count >= config['early_stop']:\n",
    "    #    print('\\nModel is not improving, so we halt the training session.')\n",
    "    #    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00d2280e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1ef88a705ae7f8a3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1ef88a705ae7f8a3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=./runs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb9648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
